name: scrape-jobs

on:
  schedule:
    - cron: "0 */6 * * *"
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install flask requests beautifulsoup4

      - name: Run scraper
        env:
          PYTHONPATH: ${{ github.workspace }}
          SCRAPE_TIMEOUT_SEC: "45"
          TARGET_JOB_COUNT: "5000"
          MAX_RUNTIME_SEC: "900"
          SCRAPE_RETRY_SLEEP_SEC: "20"
          SCRAPE_MAX_PASSES: "10"
        run: python scripts/scrape_jobs.py

      - name: Build job details snapshot
        env:
          PYTHONPATH: ${{ github.workspace }}
          JOBS_LIST_URL: "https://tokzbiepijjdvbdtacjz.supabase.co/storage/v1/object/public/jobs-info/jobs.json"
          DETAILS_LIMIT: "1200"
        run: python scripts/build_job_details.py

      - name: Upload to Supabase Storage
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          curl -X PUT "$SUPABASE_URL/storage/v1/object/jobs-info/jobs.json" \
            -H "Authorization: Bearer $SUPABASE_SERVICE_ROLE_KEY" \
            -H "apikey: $SUPABASE_SERVICE_ROLE_KEY" \
            -H "Content-Type: application/json" \
            --data-binary @jobs.json
          curl -X PUT "$SUPABASE_URL/storage/v1/object/jobs-info/jobsDetails.json" \
            -H "Authorization: Bearer $SUPABASE_SERVICE_ROLE_KEY" \
            -H "apikey: $SUPABASE_SERVICE_ROLE_KEY" \
            -H "Content-Type: application/json" \
            --data-binary @jobsDetails.json
